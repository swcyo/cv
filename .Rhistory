names(cols) = levels(df$确诊人数)
ggplot() +geom_map(aes(long, lat, map_id=id, group=group, fill=确诊人数), map=cn2, data=cn2, colour='grey') +coord_map() +scale_fill_viridis_d() +theme_bw() +xlab(NULL) + ylab(NULL) +    labs(title = '2019nCov',subtitle = paste('确诊病例:',d$chinaTotal$confirm,  "；疑似病例:",d$chinaTotal$suspect,  "；死亡人数:",d$chinaTotal$dead,"；治愈人数:",d$chinaTotal$heal), caption=paste("更新至:", d$lastUpdateTime))+ scale_fill_manual(values=cols, breaks=names(cols))
getwd()
ggplot() +geom_map(aes(long, lat, map_id=id, group=group, fill=确诊人数), map=cn2, data=cn2, colour='grey') +coord_map() +scale_fill_viridis_d() +theme_bw() +xlab(NULL) + ylab(NULL) +    labs(title = '2019nCov',subtitle = paste('确诊病例:',d$chinaTotal$confirm,  "；疑似病例:",d$chinaTotal$suspect,  "；死亡人数:",d$chinaTotal$dead,"；治愈人数:",d$chinaTotal$heal), caption=paste("更新至:", d$lastUpdateTime))+ scale_fill_manual(values=cols, breaks=names(cols))+ theme(text = element_text(family='Kai'))
View(df)
View(d)
df = data.frame(name = d$areaTree$children[[1]]$name,
确诊人数 = cut(d$areaTree$children[[1]]$total$confirm,
c(1,10,100,500,1000,10000,20000),
include.lowest = T, right=F))
cn2 = merge(cn, df, by.x='province', by.y='name', all.x=TRUE)
cn2 = cn2[order(cn2$order),]
View(df)
View(cn2)
cols = RColorBrewer::brewer.pal(6, 'Reds')
names(cols) = levels(df$确诊人数)
ggplot() +geom_map(aes(long, lat, map_id=id, group=group, fill=确诊人数), map=cn2, data=cn2, colour='grey') +coord_map() +scale_fill_viridis_d() +theme_bw() +xlab(NULL) + ylab(NULL) + labs(title = '2019nCov',subtitle = paste('确诊病例:',d$chinaTotal$confirm,  "；疑似病例:",d$chinaTotal$suspect,  "；死亡人数:",d$chinaTotal$dead,"；治愈人数:",d$chinaTotal$heal), caption=paste("更新至:", d$lastUpdateTime))+ scale_fill_manual(values=cols, breaks=names(cols))+ theme(text = element_text(family='Kai'))
ggplot() +geom_map(aes(long, lat, map_id=id, group=group, fill=确诊人数), map=cn2, data=cn2, colour='grey') +coord_map() +scale_fill_viridis_d() +theme_minimal() +xlab(NULL) + ylab(NULL) + labs(title = '2019nCov',subtitle = paste('确诊病例:',d$chinaTotal$confirm,  "；疑似病例:",d$chinaTotal$suspect,  "；死亡人数:",d$chinaTotal$dead,"；治愈人数:",d$chinaTotal$heal), caption=paste("更新至:", d$lastUpdateTime))+ scale_fill_manual(values=cols, breaks=names(cols))+ theme(text = element_text(family='Kai'))
ggplot() +geom_map(aes(long, lat, map_id=id, group=group, fill=确诊人数), map=cn2, data=cn2, colour='grey') +coord_map() +scale_fill_viridis_d() +theme_minimal() +xlab(NULL) + ylab(NULL) + labs(title = '2019nCov',subtitle = paste('确诊病例:',d$chinaTotal$confirm,  "；疑似病例:",d$chinaTotal$suspect,  "；死亡人数:",d$chinaTotal$dead,"；治愈人数:",d$chinaTotal$heal), caption=paste("更新至:", d$lastUpdateTime))
library(showtext)
library(sysfonts)
library(showtext)
par(family='STKaiti')
ggplot() +geom_map(aes(long, lat, map_id=id, group=group, fill=确诊人数), map=cn2, data=cn2, colour='grey') +coord_map() +scale_fill_viridis_d() +theme_minimal() +xlab(NULL) + ylab(NULL) + labs(title = '2019nCov',subtitle = paste('确诊病例:',d$chinaTotal$confirm,  "；疑似病例:",d$chinaTotal$suspect,  "；死亡人数:",d$chinaTotal$dead,"；治愈人数:",d$chinaTotal$heal), caption=paste("更新至:", d$lastUpdateTime))
ggplot() +geom_map(aes(long, lat, map_id=id, group=group, fill=确诊人数), map=cn2, data=cn2, colour='grey') +coord_map() +scale_fill_viridis_d() +theme_bw() +xlab(NULL) + ylab(NULL) + labs(title = '2019nCov',subtitle = paste('确诊病例:',d$chinaTotal$confirm,  "；疑似病例:",d$chinaTotal$suspect,  "；死亡人数:",d$chinaTotal$dead,"；治愈人数:",d$chinaTotal$heal), caption=paste("更新至:", d$lastUpdateTime))+ scale_fill_manual(values=cols, breaks=names(cols))+ theme(text = element_text(family='STKaiti'))
library(nCov2019)
x<-get_nCov2019()
x[]
plot(x)
write.csv("x.csv",x[])
write.csv(x[],"x.csv")
library(ggplot2)
getwd
library(devtools)
install_github('fawda123/ggord')
library(ggord)
getwd
getwd()
pca_data=read.table('all.txt',header=T,sep='\t',row=1)
View(pca_data)
pca_data=t(as.matrix(pca_data))
pca_group=factor(c(rep('1',177),rep('2',191)))
pca1=prcomp(pca_data,center=TRUE,retx=T)
p1 <- ggord(pca1,="" grp_in="pca_group," arrow="0," vec_ext="")
View(pca1)
p1<-ggord(pca1)
p1
remove(p1)
View(pca_data)
View(pca1)
write.csv(pca_data,"all.csv")
summary(pca1)
rm(list=ls())
library(ggplot2)
pca <- prcomp(USArrests,scale = TRUE)
View(pca)
head(pca)
USArrests
data<-read.table("all.txt",header = T)
View(data)
data<-read.table("all.txt",header = T,row.names = 1)
pca <- prcomp(USArrests,scale = TRUE)
head(pca)
head(pca)
pca <- prcomp(data,scale = TRUE)
head(pca)
xlab <- paste("PC1","(",round((summary(pca))$importance[2,1]*100,1),"%)",sep="")
ylab <- paste("PC2","(",round((summary(pca))$importance[2,2]*100,1),"%)",sep="")
x<-"PC1"
y<-"PC2"
data_x <- data.frame(varnames=rownames(pca$x), pca$x) #为方便取用数据，将pca结果放在一个数据库里面
plot_1 <- ggplot(data_x, aes(PC1,PC2))+geom_point(aes(color=varnames),size=3)+coord_equal(ratio=1)+xlab(xlab)+ylab(ylab) # 这里先画出点，coord_equal(ratio=1) 将X轴和y轴比例设置为一样的
data_rotation <- data.frame(obsnames=row.names(pca$rotation), pca$rotation)
mult <- min(
(max(data_x[,y]) - min(data_x[,y])/(max(data_rotation[,y])-min(data_rotation[,y]))),
(max(data_x[,x]) - min(data_x[,x])/(max(data_rotation[,x])-min(data_rotation[,x])))
)
#设置箭头坐标
data_2 <- transform(data_rotation,
v1 = mult * (get(x)),
v2 = mult * (get(y))
)
plot_1<-plot_1+geom_segment(data=data_2,aes(x=0,y=0,xend=v1,yend=v2),arrow=arrow(length=unit(0.2,"cm")),alpha=0.75)
#添加箭头名称
plot_1<-plot_1+geom_text(data=data_2,aes(v1,v2,label=obsnames),size=3,nudge_x=-0.05,nudge_y=-0.01)
#对图形结果进行修饰
plot_1 <- plot_1+scale_color_discrete(guide=guide_legend(title="stage type"))+theme_bw()+theme(plot.background=element_blank(),panel.background=element_blank(),panel.grid.minor=element_blank(),panel.grid.major=element_blank(),axis.title=element_text(color="black",size=15),axis.text=element_text(size=15))+guides(color=F)
plot_1
rm(list=ls())
df <- iris[c(1, 2, 3, 4)]
View(df)
df_pca <- prcomp(df) #计算主成分
df_pcs <-data.frame(df_pca$x, Species = iris$Species)
View(df_pca)
View(df_pcs)
View(df)
View(df_pcs)
iris
pca<-read.csv("pca.csv",row.names = 1)
View(pca)
head(iris)
df <- iris[c(1, 2, 3, 4,5,6,7,8,9)]
df <- pca[c(1, 2, 3, 4,5,6,7,8,9)]
View(df)
df_pca <- prcomp(df)
View(df_pca)
df_pcs <-data.frame(df_pca$x, class = pca$class)
head(df)
head(df_pcs,9)
head(df_pcs)
plot(df_pca$x[,1], df_pca$x[,2])
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class))+ geom_point()
percentage<-round(df_pca$sdev / sum(df_pca$sdev) * 100,2)
percentage<-paste(colnames(df_pcs),"(", paste(as.character(percentage), "%", ")", sep=""))
ggplot(df_pcs,aes(x=PC1,y=PC2,color=Species))+
geom_point()+
xlab(percentage[1]) +
ylab(percentage[2])
percentage<-round(df_pca$sdev / sum(df_pca$sdev) * 100,2)
percentage<-paste(colnames(df_pcs),"(", paste(as.character(percentage), "%", ")", sep=""))
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class)+
geom_point()+
xlab(percentage[1]) +
ylab(percentage[2])
pca<-read.csv("pca.csv",row.names = 1)
View(pca)
pca<-read.csv("pca.csv",row.names = 1)
View(pca)
df <- pca[c(1, 2, 3, 4,5,6,7,8,9)]
df_pca <- prcomp(df)
df_pcs <-data.frame(df_pca$x, class = pca$class)
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class))+ geom_point()
percentage<-round(df_pca$sdev / sum(df_pca$sdev) * 100,2)
percentage<-paste(colnames(df_pcs),"(", paste(as.character(percentage), "%", ")", sep=""))
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class))+
geom_point()+
xlab(percentage[1]) +
ylab(percentage[2])
ggplot(df_pcs,aes(x=PC1,y=PC2,color = class))+ geom_point()+stat_ellipse(level = 0.95, show.legend = F) +
annotate('text', label = 'setosa', x = -2, y = -1.25, size = 5, colour = '#f8766d') +
annotate('text', label = 'versicolor', x = 0, y = - 0.5, size = 5, colour = '#00ba38') +
annotate('text', label = 'virginica', x = 3, y = 0.5, size = 5, colour = '#619cff')
ggplot(df_pcs,aes(x=PC1,y=PC2,color = color))+ geom_point()+stat_ellipse(level = 0.95, show.legend = F) +
annotate('text', label = 'class1', x = -2, y = -1.25, size = 5, colour = '#f8766d') +
annotate('text', label = 'class2', x = 0, y = - 0.5, size = 5, colour = '#00ba38')
ggplot(df_pcs,aes(x=PC1,y=PC2,color = class))+ geom_point()+stat_ellipse(level = 0.95, show.legend = F) +
annotate('text', label = 'class1', x = -2, y = -1.25, size = 5, colour = '#f8766d') +
annotate('text', label = 'class2', x = 0, y = - 0.5, size = 5, colour = '#00ba38') +theme_bw()
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class )) + geom_point()+xlab(percentage[1]) + ylab(percentage[2]) + stat_ellipse(level = 0.95, show.legend = F)  + labs(title="PCA Clustering",  subtitle=" PC1 and PC2 principal components ",       caption="Source: pcs") + theme_bw()
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class )) + geom_point()+xlab(percentage[1]) + ylab(percentage[2]) + stat_ellipse(level = 0.95, show.legend = F)  + labs(title="PCA Clustering",  subtitle=" PC1 and PC2 principal components ",       caption="Source: pcs") + theme_bw()+coord_flip()
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class )) + geom_point()+xlab(percentage[1]) + ylab(percentage[2]) + stat_ellipse(level = 0.95, show.legend = F)  + labs(title="PCA Clustering",  subtitle=" PC1 and PC2 principal components ",       caption="Source: pcs") + theme_bw()
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class )) + geom_point()+xlab(percentage[1]) + ylab(percentage[2]) + stat_ellipse(level = 0.95, show.legend = F)  + theme_bw()
ggplot(df_pcs,aes(x=PC1,y=PC2,fill=class )) + geom_point()+xlab(percentage[1]) + ylab(percentage[2]) + stat_ellipse(level = 0.95, show.legend = F)  + theme_bw()
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class )) + geom_point(size=3)+xlab(percentage[1]) + ylab(percentage[2]) + stat_ellipse(level = 0.95, show.legend = F)  + theme_bw()
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class )) + geom_point(size=2)+xlab(percentage[1]) + ylab(percentage[2]) + stat_ellipse(level = 0.95, show.legend = F)  + theme_bw()
ggsave("pca.pdf",width = 4,height = 3)
ggsave("pca.pdf",width = 8,height = 6)
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class )) + geom_point()+xlab(percentage[1]) + ylab(percentage[2]) + stat_ellipse(level = 0.90, show.legend = F)  + theme_bw()
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class )) + geom_point()+xlab(percentage[1]) + ylab(percentage[2]) + stat_ellipse(level = 0.75, show.legend = F)  + theme_bw()
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class )) + geom_point()+xlab(percentage[1]) + ylab(percentage[2]) + stat_ellipse(level = 0.98, show.legend = F)  + theme_bw()
ggord(df_pcs, pca$class)
ggord(df_pca, pca$class)
ggord(df_pca, pca$class) + scale_shape_manual('Groups', values = c(1, 2))
ggord(df_pca, pca$class,, poly = FALSE)
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class))+
geom_point()+
xlab(percentage[1]) +
ylab(percentage[2])
ggord(df_pca, pca$class, poly = FALSE)
summary(df_pca)
View(df_pca)
install.packages("factoextra")
ggord(df_pca, grp_in = pca$class, arrow=0, vec_ext =0,txt=NULL)
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class )) + geom_point(size=1)+xlab(percentage[1]) + ylab(percentage[2]) + stat_ellipse(level = 0.95, show.legend = F)  + theme_bw()
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class )) + geom_point(size=2)+xlab(percentage[1]) + ylab(percentage[2]) + stat_ellipse(level = 0.95, show.legend = F)  + theme_bw()
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class )) + geom_point(size=3)+xlab(percentage[1]) + ylab(percentage[2]) + stat_ellipse(level = 0.95, show.legend = F)  + theme_bw()
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class )) + geom_point(size=2)+xlab(percentage[1]) + ylab(percentage[2]) + stat_ellipse(level = 0.95, show.legend = F)  + theme_bw()
ggord(df_pca, grp_in = pca$class, arrow=0, vec_ext =0,txt=NULL,size=2)
ggord(df_pca, grp_in = pca$class, arrow=0, vec_ext =0,txt=NULL,size=2,poly=F)
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class )) + geom_point(size=2)+xlab(percentage[1]) + ylab(percentage[2]) + stat_ellipse(level = 0.95, show.legend = F)  + theme_bw()
ggsave("pca.pdf",width = 4,height = 4)
ggsave("pca.pdf",width = 8,height = 7)
ggsave("pca.pdf",width = 8,height = 6)
citation("clusterProfiler")
library(clusterProfiler)
citation("glmnet")
pca<-read.csv("pca.csv",row.names = 1)
df <- pca[c(1, 2, 3, 4,5,6,7,8,9)]
df_pca <- prcomp(df)
df_pcs <-data.frame(df_pca$x, class = pca$class)
library(ggplot2)
percentage<-round(df_pca$sdev / sum(df_pca$sdev) * 100,2)
percentage<-paste(colnames(df_pcs),"(", paste(as.character(percentage), "%", ")", sep=""))
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class )) + geom_point()+xlab(percentage[1]) + ylab(percentage[2]) + stat_ellipse(level = 0.95, show.legend = F)  + theme_bw()
ggsave("p4d.pdf",width = 8,height = 8)
ggsave("p4d.pdf",width = 8,height = 6)
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class )) + geom_point()+xlab("PC1(36.83%)") + ylab("PC2(16.04%)") + stat_ellipse(level = 0.95, show.legend = F)  + theme_bw()
ggsave("p4d.pdf",width = 8,height = 6)
ggsave("p4c.pdf",width = 4,height = 4)
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class )) + geom_point()+xlab("PC1(36.83%)") + ylab("PC2(16.04%)") + stat_ellipse(level = 0.95, show.legend = F)  + theme_bw()+coord_flip()
ggplot(df_pcs,aes(x=PC1,y=PC2,color=class )) + geom_point()+xlab("PC1(36.83%)") + ylab("PC2(16.04%)") + stat_ellipse(level = 0.95, show.legend = F)  + theme_bw()
ggsave("p4c.pdf",width = 6,height = 6)
library(scholar)
install.packages("pagedown")
library(pagedown)
---
title: Song OuYang's Resume"
author: Song OuYang
date: "`r Sys.Date()`"
output:
pagedown::html_resume:
css: ['css/custom_resume.css', 'css/styles.css', 'resume']
# set it to true for a self-contained HTML page but it'll take longer to render
self_contained: true
---
```{r, include=FALSE}
knitr::opts_chunk$set(
results='asis',
echo = FALSE
)
library(tidyverse)
library(glue)
# ======================================================================
# These variables determine how the the data is loaded and how the exports are
# done.
# Is data stored in google sheets? If no data will be gather from the csvs/
# folder in project
using_googlesheets <- TRUE
# Just the copied URL from the sheet
positions_sheet_loc <- "https://docs.google.com/spreadsheets/d/14MQICF2F8-vf8CKPF1m4lyGKO6_thG-4aSwat1e2TWc"
# Is this sheet available for anyone to read? If you're using a private sheet
# set this to false and go to gather_data.R and run the data loading manually
# once to cache authentication
sheet_is_publicly_readable <- TRUE
# Is the goal of this knit to build a document that is exported to PDF? If so
# set this to true to have links turned into footnotes at the end of the
# document
PDF_EXPORT <- FALSE
# A global (gasp) variable that holds all the links that were inserted for
# placement at the end
links <- c()
# ======================================================================
# Now we source two external scripts. One contains functions for building the
# text output and the other loads up our data from either googlesheets or csvs
# Functions for building sections from CSV data
source('parsing_functions.R')
# Load data for CV/Resume
source('gather_data.R')
# Now we just need to filter down the position data to include less verbose
# categories and only the entries we have designated for the resume
position_data <- position_data %>%
filter(in_resume) %>%
mutate(
# Build some custom sections by collapsing others
section = case_when(
section %in% c('research_positions', 'industry_positions') ~ 'positions',
section %in% c('data_science_writings', 'by_me_press') ~ 'writings',
TRUE ~ section
)
)
```
Aside
================================================================================
![logo](logo.png){width=100%}
Contact {#contact}
--------------------------------------------------------------------------------
```{r}
contact_info %>%
glue_data("- <i class='fa fa-{icon}'></i> {contact}")
```
Language Skills {#skills}
--------------------------------------------------------------------------------
```{r}
build_skill_bars(skills)
```
Open Source Contributions {#open-source}
--------------------------------------------------------------------------------
All projects available at `github.com/nstrayer/<name>`
- `shinysense`: R package to use sensor data in Shiny apps
- `tuftesque`: Hugo theme (behind LiveFreeOrDichotomize.com)
- `sbmR`: R package for fitting stochasitic block models
More info {#more-info}
--------------------------------------------------------------------------------
See full CV at nickstrayer.me/cv for more complete list of positions and publications.
Disclaimer {#disclaimer}
--------------------------------------------------------------------------------
Made w/ [**pagedown**](https://github.com/rstudio/pagedown).
Source code: [github.com/nstrayer/cv](https://github.com/nstrayer/cv).
Last updated on `r Sys.Date()`.
Main
================================================================================
Nick Strayer {#title}
--------------------------------------------------------------------------------
```{r}
print_text_block(text_blocks, 'intro')
```
Education {data-icon=graduation-cap data-concise=true}
--------------------------------------------------------------------------------
```{r}
position_data %>% print_section('education')
```
Selected Positions {data-icon=suitcase}
--------------------------------------------------------------------------------
```{r}
position_data %>% print_section('positions')
```
Selected Writing {data-icon=newspaper}
--------------------------------------------------------------------------------
```{r}
position_data %>% print_section('writings')
```
---
title: "Song OuYang's CV"
author: Song OuYang
date: "`r Sys.Date()`"
output:
pagedown::html_resume:
css: ['css/styles.css', 'resume']
# set it to true for a self-contained HTML page but it'll take longer to render
self_contained: true
---
```{r, include=FALSE}
knitr::opts_chunk$set(
results='asis',
echo = FALSE
)
library(glue)
library(tidyverse)
# ======================================================================
# These variables determine how the the data is loaded and how the exports are
# done.
# Is data stored in google sheets? If no data will be gather from the csvs/
# folder in project
using_googlesheets <- TRUE
# Just the copied URL from the sheet
positions_sheet_loc <- "https://docs.google.com/spreadsheets/d/14MQICF2F8-vf8CKPF1m4lyGKO6_thG-4aSwat1e2TWc"
# Is this sheet available for anyone to read? If you're using a private sheet
# set this to false and go to gather_data.R and run the data loading manually
# once to cache authentication
sheet_is_publicly_readable <- TRUE
# Is the goal of this knit to build a document that is exported to PDF? If so
# set this to true to have links turned into footnotes at the end of the
# document
PDF_EXPORT <- FALSE
CV_PDF_LOC <- "https://github.com/nstrayer/cv/raw/master/strayer_cv.pdf"
CV_HTML_LOC <- "nickstrayer.me/cv/"
# A global (gasp) variable that holds all the links that were inserted for
# placement at the end
links <- c()
# ======================================================================
# Now we source two external scripts. One contains functions for building the
# text output and the other loads up our data from either googlesheets or csvs
# Functions for building sections from CSV data
source('parsing_functions.R')
# Load data for CV/Resume
source('gather_data.R')
```
```{r}
# When in export mode the little dots are unaligned, so fix that.
if(PDF_EXPORT){
cat("
<style>
:root{
--decorator-outer-offset-left: -6.5px;
}
</style>")
}
```
Aside
================================================================================
![logo](logo.png){width=100%}
```{r}
# When in export mode the little dots are unaligned, so fix that.
if(PDF_EXPORT){
glue("View this CV online with links at _{CV_HTML_LOC}_")
} else {
glue("[<i class='fas fa-download'></i> Download a PDF of this CV]({CV_PDF_LOC})")
}
```
Contact {#contact}
--------------------------------------------------------------------------------
```{r}
contact_info %>%
glue_data("- <i class='fa fa-{icon}'></i> {contact}")
```
Language Skills {#skills}
--------------------------------------------------------------------------------
```{r}
build_skill_bars(skills)
```
Disclaimer {#disclaimer}
--------------------------------------------------------------------------------
Made with the R package [**pagedown**](https://github.com/rstudio/pagedown).
The source code is available at [github.com/nstrayer/cv](https://github.com/nstrayer/cv).
Last updated on `r Sys.Date()`.
Main
================================================================================
Nick Strayer {#title}
--------------------------------------------------------------------------------
```{r}
print_text_block(text_blocks, 'intro')
```
Education {data-icon=graduation-cap data-concise=true}
--------------------------------------------------------------------------------
```{r}
print_section(position_data, 'education')
```
Research Experience {data-icon=laptop}
--------------------------------------------------------------------------------
```{r}
print_section(position_data, 'research_positions')
```
Industry Experience {data-icon=suitcase}
--------------------------------------------------------------------------------
::: aside
```{r}
print_text_block(text_blocks, 'industy_experience_aside')
```
:::
```{r}
print_section(position_data, 'industry_positions')
```
<!-- These breaks just force a new page so section doesnt get cut off -->
<br>
<br>
<br>
Teaching Experience {data-icon=chalkboard-teacher}
--------------------------------------------------------------------------------
::: aside
```{r}
print_text_block(text_blocks, 'teaching_experience_aside')
```
:::
```{r}
print_section(position_data, 'teaching_positions')
```
Selected Data Science Writing {data-icon=chart-line}
--------------------------------------------------------------------------------
::: aside
```{r}
print_text_block(text_blocks, 'data_science_writing_aside')
```
:::
```{r}
print_section(position_data, 'data_science_writings')
```
Selected Press (About)  {data-icon=newspaper}
--------------------------------------------------------------------------------
```{r}
print_section(position_data, 'about_me_press')
```
<br>
<br>
Selected Press (By)  {data-icon=newspaper}
--------------------------------------------------------------------------------
```{r}
print_section(position_data, 'by_me_press')
```
Selected Publications, Posters, and Talks {data-icon=book}
--------------------------------------------------------------------------------
```{r}
print_section(position_data, 'academic_articles')
```
```{r}
if(PDF_EXPORT){
cat("
Links {data-icon=link}
--------------------------------------------------------------------------------
<br>
")
walk2(links, 1:length(links), function(link, index){
print(glue('{index}. {link}'))
})
}
```
position_data％>％print_section（'education'）
install.packages("googlesheets4")
library(rmarkdown)
library(tinytex)
library(pagedown)
pagedown::html_paged
pagedown::jss_paged
pagedown::html_resume
html_resume(
...,
css = "resume",
template = pkg_resource("html", "resume.html"),
number_sections = FALSE
)
library(devtools)
remove.packages("clusterProfiler")
install_github('YuLab-SMU/clusterProfiler')
install_github('YuLab-SMU/creatKEGGdb')
install_github('YuLab-SMU/createKEGGdb')
BiocManager::install("clusterProfiler")
setwd("Documents:/Github/cv")
getwd()
setwd("Documents/Github/cv")
tinytex::install_tinytex()
library(devtools)
install_github("yihui/tinytex")
install_github("GuangchuangYu/yyplot")
remotes::install_github("GuangchuangYu/yyplot")
install.packages('tinytex')
install.packages('tinytex')
install.packages('tinytex')
install.packages("tinytex")
install.packages("pagedown")
rmarkdown::render('index.Rmd')
View(position_data)
library(rmarkdown)
knit_with_parameters('~/Documents/GitHub/cv/index.Rmd')
